{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "import pandas as pd\n",
    "\n",
    "# Set your API key\n",
    "quandl.ApiConfig.api_key = \"tw2sxkKZo_y1UvMcnSux\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading tickers...\n",
      "{'datatable_bulk_download': {'file': {'link': 'https://aws-gis-link-pro-us-east-1-datahub.s3.amazonaws.com/export/QUOTEMEDIA/TICKERS/QUOTEMEDIA_TICKERS_6d75499fefd916e54334b292986eafcc.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAX5EW3SB5FG5CDO5I%2F20241018%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241018T164046Z&X-Amz-Expires=1800&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEOH%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQD730f7KMHsQDdQpYn1uV5y%2B3AGuX6HsbNwGXqzbXbOagIgCwVTN%2BLcnj0wReqV%2Bbjn%2BxfV5RJx%2BMZkC6EDRMEQtuMqjAUIShACGgw1NDM2Mjk3NDIyMDIiDMMQWCsZlrBteW1RVSrpBEhBRZwxujQC8hx8XXcJijdOe5YBJX8lJlqHD%2FwctNiULkDWGbncpaQK9eGxxc38IJ6hVsy8P%2FArKgSpc2KX6rYYFHU4CuL3pwGXv%2Bj9TK3O0WZ7m%2FsXA5J6a8sVWTrSpEDjNQImssPXoUrJ1a5B%2FZcj3MAnPCLG8uHNYBAQgwF6AsRuSRtuGTxF85scmo8PT4IherH3IXi46ZZwDwc5KHr7HnMc5DlVIVw224J3poaCqvm0CFmm%2FuP%2FfoI6gxW6o%2BnDpPuCYrb4F6Cxf0HXMXpzcH4evVcL3T%2BDw%2FJ9SLBA1uYDPsi9mvkDg%2BfgUtkAty4P60UcHL6vyJ7CdUyA50G0X%2BBGRrVVyLmhLIdy8Y8yAm2c6yOCxR4FsHukSz%2BiQ%2B%2FeX%2BP%2FIySdJqVE8BV8iVFRrP1w4B%2FLQCF84l%2Bj%2BiW4SUvD9rwx0P9ybfLuyM%2B%2BKeHuuJWilJPf%2B69UnqDsbDW08k43KyYDOBfIcRBLMk%2FS36UNxoPPpiMbgSODnY6I7Nedtl1fpdrZI%2Fv38YxCQ1D9%2B2EoRP%2F9ymb6hNpVYoYIlVCGTHmeeIF4nJzWROtpfw2a4mN5a5uUFRDJcg58T7aXJ15W40jv%2FLkSINcjmJejjZfMDNJawzuY2LikjQ4fORX%2BeZkX7MqVtX3nWtRWWOIsslk2NTSTBNFeTKwRU0N6vWwe%2BEEVCo8BavMvQ8P0HWu9lfXYLaJTuypJB6R6ScE8jRMuV%2FeSVu1IXPjs4avPJLtOvgSMzBD9LGOV%2BUHtT4RKHuK66PkyxT49WFU3iYwHQwrwTsCf%2FIq2o7X7MinazfwMWoQcXCbGMI6fyrgGOpoBIYll7Ka71SnmPCWT4N7co22X8DJQbbB%2Fsq7szqexB%2FTdti2mkPpYX3CGyRRKT6XS2v30UojmFM%2Fea%2FVxluiL6f2lpcWqFLiAsfGQUHVmaQjm2EBJ%2BD6gfUu9WlV9giQShcVVY3dGpYQWCZ8Bkd4PcSPK%2BCkuwxavMbJxYap2Zfy5%2BMeReQZgLlSCgK4Am5GLbhBDUuH120RRoQ%3D%3D&X-Amz-SignedHeaders=host&X-Amz-Signature=28a02eb8282fae7c0f5342016c73a2e1496121580c6001105adb1990315ca0d6', 'status': 'fresh', 'data_snapshot_time': '2024-10-18 01:33:20 UTC'}, 'datatable': {'last_refreshed_time': '2024-10-18 00:09:06 UTC'}}}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'datatable'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Download tickers\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading tickers...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m tickers_data \u001b[38;5;241m=\u001b[39m \u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTICKERS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mqopts.export\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m tickers_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(tickers_data, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mticker\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexchange\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompany_name\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Download price data\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(endpoint, params)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mjson())\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatatable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI request failed with status code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'datatable'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import h5py\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set up API key and base URL\n",
    "API_KEY = \"tw2sxkKZo_y1UvMcnSux\"\n",
    "BASE_URL = \"https://data.nasdaq.com/api/v3/datatables/QUOTEMEDIA\"\n",
    "\n",
    "# Function to download data from API\n",
    "def get_data(endpoint, params):\n",
    "    url = f\"{BASE_URL}/{endpoint}\"\n",
    "    params[\"api_key\"] = API_KEY\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        print(response.json())\n",
    "        return response.json()[\"datatable\"][\"data\"]\n",
    "    else:\n",
    "        raise Exception(f\"API request failed with status code {response.status_code}\")\n",
    "\n",
    "# Download tickers\n",
    "print(\"Downloading tickers...\")\n",
    "tickers_data = get_data(\"TICKERS\", {\"qopts.export\": \"true\"})\n",
    "tickers_df = pd.DataFrame(tickers_data, columns=[\"ticker\", \"exchange\", \"company_name\"])\n",
    "\n",
    "# Download price data\n",
    "print(\"Downloading price data...\")\n",
    "start_date = \"2000-01-01\"\n",
    "end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "prices_data = []\n",
    "for ticker in tickers_df[\"ticker\"]:\n",
    "    print(f\"Downloading data for {ticker}\")\n",
    "    params = {\n",
    "        \"ticker\": ticker,\n",
    "        \"date.gte\": start_date,\n",
    "        \"date.lte\": end_date,\n",
    "        \"qopts.columns\": \"ticker,date,open,high,low,close,volume,dividend,split,adj_open,adj_high,adj_low,adj_close,adj_volume\"\n",
    "    }\n",
    "    prices_data.extend(get_data(\"PRICES\", params))\n",
    "\n",
    "prices_df = pd.DataFrame(prices_data, columns=[\"ticker\", \"date\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"dividend\", \"split\", \"adj_open\", \"adj_high\", \"adj_low\", \"adj_close\", \"adj_volume\"])\n",
    "\n",
    "# Convert date column to datetime\n",
    "prices_df[\"date\"] = pd.to_datetime(prices_df[\"date\"])\n",
    "\n",
    "# Store data in H5 format\n",
    "print(\"Storing data in H5 format...\")\n",
    "with h5py.File(\"quotemedia_eod_data.h5\", \"w\") as f:\n",
    "    # Store tickers data\n",
    "    tickers_group = f.create_group(\"tickers\")\n",
    "    for column in tickers_df.columns:\n",
    "        tickers_group.create_dataset(column, data=tickers_df[column].values)\n",
    "    \n",
    "    # Store prices data\n",
    "    prices_group = f.create_group(\"prices\")\n",
    "    for column in prices_df.columns:\n",
    "        if column == \"date\":\n",
    "            prices_group.create_dataset(column, data=prices_df[column].astype(int))\n",
    "        else:\n",
    "            prices_group.create_dataset(column, data=prices_df[column].values)\n",
    "\n",
    "print(\"Data successfully stored in quotemedia_eod_data.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading tickers...\n",
      "Downloading price data...\n",
      "Downloading data for BIOA_WS\n"
     ]
    },
    {
     "ename": "MissingSchema",
     "evalue": "Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 58\u001b[0m\n\u001b[1;32m     56\u001b[0m     price_response \u001b[38;5;241m=\u001b[39m get_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRICES\u001b[39m\u001b[38;5;124m\"\u001b[39m, params)\n\u001b[1;32m     57\u001b[0m     price_download_link \u001b[38;5;241m=\u001b[39m price_response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatatable_bulk_download\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 58\u001b[0m     price_df \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_and_process_zip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprice_download_link\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     prices_data\u001b[38;5;241m.\u001b[39mappend(price_df)\n\u001b[1;32m     61\u001b[0m prices_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(prices_data, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[7], line 25\u001b[0m, in \u001b[0;36mdownload_and_process_zip\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_and_process_zip\u001b[39m(url):\n\u001b[0;32m---> 25\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     27\u001b[0m         z \u001b[38;5;241m=\u001b[39m zipfile\u001b[38;5;241m.\u001b[39mZipFile(io\u001b[38;5;241m.\u001b[39mBytesIO(response\u001b[38;5;241m.\u001b[39mcontent))\n",
      "File \u001b[0;32m~/anaconda3/envs/zip312/lib/python3.12/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/zip312/lib/python3.12/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/zip312/lib/python3.12/site-packages/requests/sessions.py:575\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# Create the Request.\u001b[39;00m\n\u001b[1;32m    563\u001b[0m req \u001b[38;5;241m=\u001b[39m Request(\n\u001b[1;32m    564\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod\u001b[38;5;241m.\u001b[39mupper(),\n\u001b[1;32m    565\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    573\u001b[0m     hooks\u001b[38;5;241m=\u001b[39mhooks,\n\u001b[1;32m    574\u001b[0m )\n\u001b[0;32m--> 575\u001b[0m prep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m proxies \u001b[38;5;241m=\u001b[39m proxies \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    579\u001b[0m settings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge_environment_settings(\n\u001b[1;32m    580\u001b[0m     prep\u001b[38;5;241m.\u001b[39murl, proxies, stream, verify, cert\n\u001b[1;32m    581\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/zip312/lib/python3.12/site-packages/requests/sessions.py:484\u001b[0m, in \u001b[0;36mSession.prepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    481\u001b[0m     auth \u001b[38;5;241m=\u001b[39m get_netrc_auth(request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    483\u001b[0m p \u001b[38;5;241m=\u001b[39m PreparedRequest()\n\u001b[0;32m--> 484\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCaseInsensitiveDict\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcookies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerged_cookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m~/anaconda3/envs/zip312/lib/python3.12/site-packages/requests/models.py:367\u001b[0m, in \u001b[0;36mPreparedRequest.prepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Prepares the entire request with the given parameters.\"\"\"\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_method(method)\n\u001b[0;32m--> 367\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_headers(headers)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_cookies(cookies)\n",
      "File \u001b[0;32m~/anaconda3/envs/zip312/lib/python3.12/site-packages/requests/models.py:438\u001b[0m, in \u001b[0;36mPreparedRequest.prepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(\u001b[38;5;241m*\u001b[39me\u001b[38;5;241m.\u001b[39margs)\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m scheme:\n\u001b[0;32m--> 438\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingSchema(\n\u001b[1;32m    439\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid URL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: No scheme supplied. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerhaps you meant https://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    441\u001b[0m     )\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m host:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid URL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: No host supplied\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mMissingSchema\u001b[0m: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import h5py\n",
    "from datetime import datetime, timedelta\n",
    "import io\n",
    "import zipfile\n",
    "\n",
    "# Set up API key and base URL\n",
    "API_KEY = \"tw2sxkKZo_y1UvMcnSux\"\n",
    "BASE_URL = \"https://data.nasdaq.com/api/v3/datatables/QUOTEMEDIA\"\n",
    "\n",
    "# Function to download data from API\n",
    "def get_data(endpoint, params):\n",
    "    url = f\"{BASE_URL}/{endpoint}\"\n",
    "    params[\"api_key\"] = API_KEY\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"API request failed with status code {response.status_code}\")\n",
    "\n",
    "# Function to download and process ZIP file\n",
    "def download_and_process_zip(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        z = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "        csv_filename = z.namelist()[0]  # Assume the first file in the ZIP is the CSV we want\n",
    "        with z.open(csv_filename) as f:\n",
    "            df = pd.read_csv(f)\n",
    "        return df\n",
    "    else:\n",
    "        raise Exception(f\"Failed to download ZIP file. Status code: {response.status_code}\")\n",
    "\n",
    "# Download tickers\n",
    "print(\"Downloading tickers...\")\n",
    "tickers_response = get_data(\"TICKERS\", {\"qopts.export\": \"true\"})\n",
    "download_link = tickers_response['datatable_bulk_download']['file']['link']\n",
    "tickers_df = download_and_process_zip(download_link)\n",
    "\n",
    "# Download price data\n",
    "print(\"Downloading price data...\")\n",
    "start_date = \"2000-01-01\"\n",
    "end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "prices_data = []\n",
    "for ticker in tickers_df[\"ticker\"]:\n",
    "    print(f\"Downloading data for {ticker}\")\n",
    "    params = {\n",
    "        \"ticker\": ticker,\n",
    "        \"date.gte\": start_date,\n",
    "        \"date.lte\": end_date,\n",
    "        \"qopts.columns\": \"ticker,date,open,high,low,close,volume,dividend,split,adj_open,adj_high,adj_low,adj_close,adj_volume\",\n",
    "        \"qopts.export\": \"true\"\n",
    "    }\n",
    "    price_response = get_data(\"PRICES\", params)\n",
    "    price_download_link = price_response['datatable_bulk_download']['file']['link']\n",
    "    price_df = download_and_process_zip(price_download_link)\n",
    "    prices_data.append(price_df)\n",
    "\n",
    "prices_df = pd.concat(prices_data, ignore_index=True)\n",
    "\n",
    "# Convert date column to datetime\n",
    "prices_df[\"date\"] = pd.to_datetime(prices_df[\"date\"])\n",
    "\n",
    "# Store data in H5 format\n",
    "print(\"Storing data in H5 format...\")\n",
    "with h5py.File(\"quotemedia_eod_data.h5\", \"w\") as f:\n",
    "    # Store tickers data\n",
    "    tickers_group = f.create_group(\"tickers\")\n",
    "    for column in tickers_df.columns:\n",
    "        tickers_group.create_dataset(column, data=tickers_df[column].values)\n",
    "    \n",
    "    # Store prices data\n",
    "    prices_group = f.create_group(\"prices\")\n",
    "    for column in prices_df.columns:\n",
    "        if column == \"date\":\n",
    "            prices_group.create_dataset(column, data=prices_df[column].astype(int))\n",
    "        else:\n",
    "            prices_group.create_dataset(column, data=prices_df[column].values)\n",
    "\n",
    "print(\"Data successfully stored in quotemedia_eod_data.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading tickers...\n",
      "{'datatable_bulk_download': {'file': {'link': 'https://aws-gis-link-pro-us-east-1-datahub.s3.amazonaws.com/export/QUOTEMEDIA/TICKERS/QUOTEMEDIA_TICKERS_6d75499fefd916e54334b292986eafcc.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAX5EW3SB5JQJRXSJV%2F20241018%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241018T165223Z&X-Amz-Expires=1800&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEOH%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJIMEYCIQDg%2B0CfllAPUBsaMAruA%2BwKmLHCHrqAUoqhj21GUKjzCwIhAJFrRRJxSPqT93X7euhvrxyaUkAPr2JxFCthGM6tNYzVKowFCEoQAhoMNTQzNjI5NzQyMjAyIgz8qyWm9E1fWKVuTUgq6QSSE9mH1yqc%2FLhUe835lbccBlu3tIrbLHMbZ9OGwjmmRdzYh0YruKjf9PFzSWmTaVmBfrmNdKw80lu%2FfYUns%2F1Wq09JBIw1FJagdadLpIP6A7LC8sVbC4DZOWp%2Fe1lFHHMi7Qo6dyRUfuw%2BwceDX7XH6%2FCkAXe%2BL9Y7ZwWvdPIOLuYrNwNcB2SUPGb6jE0fgt01iDP6UQX0kaDc0dpzU4sMNvGO0OCuAr1Y9VCRLBWo2A0SVsPu8%2FMAFUhbws2dCAe5Lc1fSHKJk5oh4%2BcoMvoZ0X40qexzSNX7hM%2FFICkloxpnzuZhhKzNfxwJ%2FwhwrAsatjj2cSfmRyy%2Bjolx1SBomTgkaQhfpUndD85jUEgWVoXjFBK34Xa84UV0LIAWortSAdDMEkgyOEIq7OT3qe4Ojqb%2FfaAGjNp6xLrRCb3xbI1uFvxEB5xaIIDHPgqKvrIt3J6gVskWD3He%2F6bx8aitSnTt3T%2FzCh9LDgKkd0jRFPwGhMA5FKVMWHhw2lAhhZY9B7KkESvURlhg9vo6Jyk44dYarRqj%2F7Hj2%2FzI4AUvcJFASqb%2BSvaJm2cwi%2FFMSbKOOjE6%2FB70O6TcYi7Rm38aj1q26cTOwT1NHaXQ13TKjDpDVaU63ahJE6GnpQeWJbmL4zJ1bQP3fPiuU%2FqXEww3z2b%2BGFxsjwtf7tJEwVIEbDOJ%2BFgk%2BX2khu94VZgmPLO2cqy0lN2iC7nMEa5oKgUAKMXmMp969cbSKoaTwakZoeebWQsbqfQZkM7FSZ2MkLwq7cBnqWvNb6fRpE88rRzl6%2BYfmtRcxzH%2BhntlpnfIlXtuye1rcGqefzDHpMq4BjqZAe5TacEkB1t0ZWjMaPkiOfc%2Bbf5z2VoeODDvqE0%2FoHwFeeYzcacOgycix%2Bi5mkEP%2BmpzSgJtQ1d6Qs1Uleoaxfx%2F3v%2Fq1Gx%2FM14hRv3194v%2Fa8LLpOD60TVsTB%2FCo17wDnIolV7%2BIMd3TX6ot1NwEQXWdXHdaBkND9gFZ2cuQtg9BzgLCpcGL9%2FirpboRR4xILkHldS2ZNdOxw%3D%3D&X-Amz-SignedHeaders=host&X-Amz-Signature=ed9bf27414268a4748e693d3cc4a1207ab214c52f019096703647b5c2fd9d2d9', 'status': 'fresh', 'data_snapshot_time': '2024-10-18 01:33:20 UTC'}, 'datatable': {'last_refreshed_time': '2024-10-18 00:09:06 UTC'}}}\n",
      "Downloading price data...\n",
      "Downloading data for BIOA_WS\n",
      "{'datatable_bulk_download': {'file': {'link': 'https://aws-gis-link-pro-us-east-1-datahub.s3.amazonaws.com/export/QUOTEMEDIA/PRICES/QUOTEMEDIA_PRICES_0fb2e35aff0badabd3d3ec13bb8c9ae9.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAX5EW3SB5P5D6PODP%2F20241018%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241018T165225Z&X-Amz-Expires=1800&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEOH%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQCHE%2FbLPqNUF8%2B4eOXmab4%2B7FuO3XplQDG2NyPK5HT%2FAAIgUGOVy7gZKz0nw5a1WAq%2BGQ15Xn%2FZhskgly6AhdQkWSwqjAUIShACGgw1NDM2Mjk3NDIyMDIiDE9awjtwaS%2BmZCtBDSrpBAMBCOvFjd7R1yYVt830EjxsPk%2BZuHDA3gSwAwfW7uVQKNm9UFT%2BMtno%2F%2B0uXMq9MA%2FDwUC94zKx%2BeO67PCeeC3u66RKCPO7zb5AL12%2BXAqqW2IWdO13T4Ft6BrK%2Fok8HeeTI3v1K7JnopJscTeDVAB0%2BVgAFvdWca%2FR4rWEJyhdikbD2vHCAXIv7F4TE4vrPTl%2FB15gYEqtTkRlYf2g%2BI1TjNCwSn989iRyt%2BEqljQ3ODZ7axvb55y%2B0HB5Gv5li2FL%2BvMzbMSt5zA%2Bqsp88q%2BOxL5sY0fLWFAvorLPUnlTM6K%2FJtKN%2B4T3ltzSjyjRFpblt8GcGKjbUHfZHtLr35vJXPCuqysqxzNVq0k8yGBOz275KFWVvM18gcPElxfv0ql1k525D9j614%2BB%2BQ6QV8n7iMhAFTnZXrHVKnuGmeQJcnSYek8BPKBqksDPSm8FYgIl6HKJToydxy%2Fn2BliYq7ByuX1BuAr1cPsMz4e6u0HmhbM79iqIJucESvH7gPLb7lzJW6TXEDlwis%2Fx%2Bn7GLGwAWO3oXcLbbWKRs7LVSarg8kcZk1j8q9RFD32fniEENY0XnfnTyGRHMHDXcEOyEXG59POH9E6WOGf6dzfGAaG1viylP64UHvvu5Z4tAp6xfBlQnR9%2B5Oq3%2FyjsLryZUr6%2B7hcrLnYh053nm1o%2BOa3zkzFHn9xtCFAj2peGbviJQOw1v3lT7mWQkjkRRpqDUsYUtOdrY%2FnP0MPY%2B5K%2FNzoQxocujNwHiAW0aECOSEwefwX24tylEyEZWI72qQwjvJSAS7uCAZxA6o8vJNJFbEH%2B4cqYMsrvlTLMMmkyrgGOpoBphUPw6CHIkDwlh1pf4kPcqMTm%2Fcz5PJDZTpzw5yXpush1IqqkO6FRQTv6ZSkTr85WqLZRZWvw5In%2B%2FNyJE8aoLMJW6pDZR9nniUNSWHUTx%2FfK4k7Wu7vebLwIcIrXqvd%2FkxvkGhyLVVzpU7P0bRdIrI5BOyOp3BxEFwiRuLFXYBnIF2IKgz1qH9IK8MvLwxEi3FBzCy5UTx4QA%3D%3D&X-Amz-SignedHeaders=host&X-Amz-Signature=3d6652f254ff2208a1bdfc377738612d9fd5be732f2318767d358d91c7768fdd', 'status': 'fresh', 'data_snapshot_time': '2024-10-18 16:42:36 UTC'}, 'datatable': {'last_refreshed_time': '2024-10-18 00:12:21 UTC'}}}\n",
      "Downloading data for CDE_WS\n",
      "{'datatable_bulk_download': {'file': {'link': 'https://aws-gis-link-pro-us-east-1-datahub.s3.amazonaws.com/export/QUOTEMEDIA/PRICES/QUOTEMEDIA_PRICES_3c61bfcac6b11fe9cecdc2c27bda6dd4.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAX5EW3SB5KUQIOB5D%2F20241018%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241018T165225Z&X-Amz-Expires=1800&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEOH%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJIMEYCIQCS%2FxfFo1B%2F7LRuybAM9qlO5bgSL%2F2kDObESYBkspOQfgIhAKaMPLRBbTwlC6Uj03cZP8PVwo4ZxPDxZ%2FvIjWh8x1d2KowFCEoQAhoMNTQzNjI5NzQyMjAyIgwXWFyt4eAmTR50Wngq6QSHLnwK5owPeeggORtGrgzf%2BfhSIPw6YmEFMC%2BmhLV4OeaUtxRs9HPF%2Bpqq3qjEn74KpZxSlH2q%2Bs27wpaN0VCH%2FgfQIYav%2B%2BlcOoGKCZU21nU4cMnT45lZ1rNdBncsd3M3e7X6uhQDeulnnA%2B9i5UGDE%2BHgV7rCZDTtap6FJTXjZnLxEVd3eoXN1Tu3CIsFUCCHpjdyS6XVWpLGq6YmT6Hjj2JR65D%2Fka1QYdpbPearVeyFYayPJqjjNjitzHZP6I9eumr0jo8DFUbxyeDylTnu60CYkwtBvBrZOB5zGvWc82GZ7ZRMak%2BUFwrTINe3LoY4iIvcWwBacX%2FLv7BxeIm%2B5KrMnufLkfuH0LZk5z63VGN2XUF1YD3bgCEi0ee%2BCKNWWYQCXlMqW9SQ2fRscvqNVAsqoM25BHv6phMf6LZtyOr0e%2BsjeD5nncJkafLmBsus94q4wTQ618pc%2Bu7lWMmvOCuFZlwuQeN4bZdO9XVzQ%2F%2FfON1J3BtWkPk6AyD1%2BzWKPfQq5OYKnLFYlZ4FQRpOifPmkv42i%2FT9ErTPvgqqMJgaQFOn0hpTyRnFRPJBxZfxxLjTKprH9ucos0ysVnmCQ290PgacfasJS348WX2OLVZ1VPSIAUhnX4qnBtOYq5f6skEx6rTnFrmcUtLDy1poPHF0K%2FRcb%2BIfPHu%2B7o6AXHWYA4keYXWv4IPkoWsn8PmPNhmSz6JHpnXOhwC9S824dudMMFC84CMMftioCi0ZE8Wi1WKVRKAKs4yjJOhEj5B%2BZlgFlMkGHRv0hzA16swGofc2701SzcVZm7V0ml%2FaF0hVrPpfPqePzDJpMq4BjqZAcpksMpFYQY28WLTmNlzk71zf6bEaWV8%2Fp5ZzIyRqGaLntJFrUcoQJAMf0B%2BaS82bTjulD2caeZMhqcG5%2F4tKqGYRsh5hH2m6fTVEVccRd%2B8pheYPuMhSsExB8fD6%2BjmaYLpZnEwzOuXEpKXKgGVnNjQY2AH%2BF5ccmQSWWnR1ydLQT2qvVeQGyEnb1Nok0CpUSxDWlvF6MmVsQ%3D%3D&X-Amz-SignedHeaders=host&X-Amz-Signature=d2e6ae09605c080d15884ad4b495251e0506993fda6e01ed5b8d352cbe2b6407', 'status': 'fresh', 'data_snapshot_time': '2024-10-18 16:45:05 UTC'}, 'datatable': {'last_refreshed_time': '2024-10-18 00:12:21 UTC'}}}\n",
      "Downloading data for FINQ\n",
      "{'datatable_bulk_download': {'file': {'link': None, 'status': 'creating', 'data_snapshot_time': None}, 'datatable': {'last_refreshed_time': '2024-10-18 00:12:21 UTC'}}}\n"
     ]
    },
    {
     "ename": "MissingSchema",
     "evalue": "Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 61\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatatable_bulk_download\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m price_response \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m price_response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatatable_bulk_download\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     60\u001b[0m     price_download_link \u001b[38;5;241m=\u001b[39m price_response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatatable_bulk_download\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 61\u001b[0m     price_df \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_and_process_zip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprice_download_link\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     prices_data\u001b[38;5;241m.\u001b[39mappend(price_df)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatatable\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m price_response \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m price_response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatatable\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "Cell \u001b[0;32mIn[9], line 26\u001b[0m, in \u001b[0;36mdownload_and_process_zip\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_and_process_zip\u001b[39m(url):\n\u001b[0;32m---> 26\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     28\u001b[0m         z \u001b[38;5;241m=\u001b[39m zipfile\u001b[38;5;241m.\u001b[39mZipFile(io\u001b[38;5;241m.\u001b[39mBytesIO(response\u001b[38;5;241m.\u001b[39mcontent))\n",
      "File \u001b[0;32m~/anaconda3/envs/zip312/lib/python3.12/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/zip312/lib/python3.12/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/zip312/lib/python3.12/site-packages/requests/sessions.py:575\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# Create the Request.\u001b[39;00m\n\u001b[1;32m    563\u001b[0m req \u001b[38;5;241m=\u001b[39m Request(\n\u001b[1;32m    564\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod\u001b[38;5;241m.\u001b[39mupper(),\n\u001b[1;32m    565\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    573\u001b[0m     hooks\u001b[38;5;241m=\u001b[39mhooks,\n\u001b[1;32m    574\u001b[0m )\n\u001b[0;32m--> 575\u001b[0m prep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m proxies \u001b[38;5;241m=\u001b[39m proxies \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    579\u001b[0m settings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge_environment_settings(\n\u001b[1;32m    580\u001b[0m     prep\u001b[38;5;241m.\u001b[39murl, proxies, stream, verify, cert\n\u001b[1;32m    581\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/zip312/lib/python3.12/site-packages/requests/sessions.py:484\u001b[0m, in \u001b[0;36mSession.prepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    481\u001b[0m     auth \u001b[38;5;241m=\u001b[39m get_netrc_auth(request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    483\u001b[0m p \u001b[38;5;241m=\u001b[39m PreparedRequest()\n\u001b[0;32m--> 484\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCaseInsensitiveDict\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcookies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerged_cookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m~/anaconda3/envs/zip312/lib/python3.12/site-packages/requests/models.py:367\u001b[0m, in \u001b[0;36mPreparedRequest.prepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Prepares the entire request with the given parameters.\"\"\"\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_method(method)\n\u001b[0;32m--> 367\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_headers(headers)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_cookies(cookies)\n",
      "File \u001b[0;32m~/anaconda3/envs/zip312/lib/python3.12/site-packages/requests/models.py:438\u001b[0m, in \u001b[0;36mPreparedRequest.prepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(\u001b[38;5;241m*\u001b[39me\u001b[38;5;241m.\u001b[39margs)\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m scheme:\n\u001b[0;32m--> 438\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingSchema(\n\u001b[1;32m    439\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid URL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: No scheme supplied. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerhaps you meant https://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    441\u001b[0m     )\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m host:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid URL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: No host supplied\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mMissingSchema\u001b[0m: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import h5py\n",
    "from datetime import datetime, timedelta\n",
    "import io\n",
    "import zipfile\n",
    "\n",
    "# Set up API key and base URL\n",
    "API_KEY = \"tw2sxkKZo_y1UvMcnSux\"\n",
    "BASE_URL = \"https://data.nasdaq.com/api/v3/datatables/QUOTEMEDIA\"\n",
    "\n",
    "# Function to download data from API\n",
    "def get_data(endpoint, params):\n",
    "    url = f\"{BASE_URL}/{endpoint}\"\n",
    "    params[\"api_key\"] = API_KEY\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        print(response.json())\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"API request failed with status code {response.status_code}\")\n",
    "\n",
    "# Function to download and process ZIP file\n",
    "def download_and_process_zip(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        z = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "        csv_filename = z.namelist()[0]  # Assume the first file in the ZIP is the CSV we want\n",
    "        with z.open(csv_filename) as f:\n",
    "            df = pd.read_csv(f)\n",
    "        return df\n",
    "    else:\n",
    "        raise Exception(f\"Failed to download ZIP file. Status code: {response.status_code}\")\n",
    "\n",
    "# Download tickers\n",
    "print(\"Downloading tickers...\")\n",
    "tickers_response = get_data(\"TICKERS\", {\"qopts.export\": \"true\"})\n",
    "download_link = tickers_response['datatable_bulk_download']['file']['link']\n",
    "tickers_df = download_and_process_zip(download_link)\n",
    "\n",
    "# Download price data\n",
    "print(\"Downloading price data...\")\n",
    "start_date = \"2000-01-01\"\n",
    "end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "prices_data = []\n",
    "for ticker in tickers_df[\"ticker\"]:\n",
    "    print(f\"Downloading data for {ticker}\")\n",
    "    params = {\n",
    "        \"ticker\": ticker,\n",
    "        \"date.gte\": start_date,\n",
    "        \"date.lte\": end_date,\n",
    "        \"qopts.columns\": \"ticker,date,open,high,low,close,volume,dividend,split,adj_open,adj_high,adj_low,adj_close,adj_volume\",\n",
    "        \"qopts.export\": \"true\"\n",
    "    }\n",
    "    price_response = get_data(\"PRICES\", params)\n",
    "    \n",
    "    if 'datatable_bulk_download' in price_response and 'file' in price_response['datatable_bulk_download']:\n",
    "        price_download_link = price_response['datatable_bulk_download']['file']['link']\n",
    "        price_df = download_and_process_zip(price_download_link)\n",
    "        prices_data.append(price_df)\n",
    "    elif 'datatable' in price_response and 'data' in price_response['datatable']:\n",
    "        price_df = pd.DataFrame(price_response['datatable']['data'], columns=price_response['datatable']['columns'])\n",
    "        prices_data.append(price_df)\n",
    "    else:\n",
    "        print(f\"No data available for {ticker}\")\n",
    "\n",
    "if prices_data:\n",
    "    prices_df = pd.concat(prices_data, ignore_index=True)\n",
    "\n",
    "    # Convert date column to datetime\n",
    "    prices_df[\"date\"] = pd.to_datetime(prices_df[\"date\"])\n",
    "\n",
    "    # Store data in H5 format\n",
    "    print(\"Storing data in H5 format...\")\n",
    "    with h5py.File(\"quotemedia_eod_data.h5\", \"w\") as f:\n",
    "        # Store tickers data\n",
    "        tickers_group = f.create_group(\"tickers\")\n",
    "        for column in tickers_df.columns:\n",
    "            tickers_group.create_dataset(column, data=tickers_df[column].values)\n",
    "        \n",
    "        # Store prices data\n",
    "        prices_group = f.create_group(\"prices\")\n",
    "        for column in prices_df.columns:\n",
    "            if column == \"date\":\n",
    "                prices_group.create_dataset(column, data=prices_df[column].astype(int))\n",
    "            else:\n",
    "                prices_group.create_dataset(column, data=prices_df[column].values)\n",
    "\n",
    "    print(\"Data successfully stored in quotemedia_eod_data.h5\")\n",
    "else:\n",
    "    print(\"No price data available to store.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading tickers...\n",
      "sending request https://data.nasdaq.com/api/v3/datatables/QUOTEMEDIA/TICKERS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response <Response [200]> <bound method Response.json of <Response [200]>>\n",
      "Downloading data from https://aws-gis-link-pro-us-east-1-datahub.s3.amazonaws.com/export/QUOTEMEDIA/TICKERS/QUOTEMEDIA_TICKERS_6d75499fefd916e54334b292986eafcc.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAX5EW3SB5ERDDLE6Q%2F20241018%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241018T174557Z&X-Amz-Expires=1800&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEOL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJIMEYCIQDYlA1y7Xh76b9sx3QQvdHfFf5kqeWqGXCDdAFhK2%2F2LAIhANr8nDakWxeCtd9AduMmhsroj8cr6QWEhYRIUk%2FJdhWJKowFCEsQAhoMNTQzNjI5NzQyMjAyIgyWdDXVehh2SLSM4Loq6QTrERzPMQFv6GKySRsla3JQWNR8AE049sibv6GAwtFo66J0Qwum5OHVsL342OrbZQupDNB5Ke%2Fe9eRUc5E61OGVo3Jd5oqxY2cIj%2BzB2%2BqevHbRiaSkPK5BQqF9DnpYAB4GxmhCFaXaX04oOFk6PzC%2BcauDyqO1RTs7E2UsGPGSuQf5kuEEJBmuizMjJFKZRX1aFubWolQxpz52F%2B7z9m57OaZfbuJ3YZ1s%2FP48YikT1O4rXE%2FTNBmhnGdPvaufvShcaR8DlwY5P0t76crpJkiDQ2x0W8AimKoht0qFblWawL7OsLO%2FeImB5rigL4C98RuUFSixCUis5O4wkwVPA7boEmS4sIW9Hm4EpQ%2BujCtov6BOEfYeN23tdo3m1kX%2FgHG29FmnUuHn3w%2Bvc0cNpVjHoF8%2B%2FLMNF3smdN1Wq0dhD5NrVYLjhRchiJAEPXMNWieF%2BqVK3YabuyPRjgqKnf7oIZ%2FNjErww8JrKVcfBEcp3FmxNZ%2FSrl6ylsNw1rHtMig3NmHY9scTr3Eu75nDUPNdBEmGweusFl4pMRIm6Ml%2B8GBXw34mFsS1u2cos10zG%2FiYU7JDaIa9FhGKvg6AZRLxFkb71he5rPHwouOH%2BqUdqG615bD7s91NcGMrfFejViZyrDAw8mT3wrqm2VrdOcFT%2BWDKOWjwv1HKaH6OvcrGe5Hbj%2FrSDeqHRzsxcUc35axv5qKvLQaHw6w%2FB2keWWSAlx6qZ9O2TkH2wKgdSFS30YoAB%2Fv55ZkJT0kZ3%2F7a3Zon06O%2F6ZnVl7mOzU2gfuKEXP2weMY5Q3lJ9Ugy2v56HwBnHb3%2BW2uogTDVvcq4BjqZAf0ceDX9vsMLqTES%2B9mgQKBcykN3Gf86j8UcNd%2FGRAP5m0mglcRzPvW4Oo1p9jSsq9Q11fBJTajy5ZnBJlc2l%2BAmJS2UrCPLgchJ%2B0Y9%2BhU%2Bemj%2FPIFX3DxJ8%2B1axf%2Ff%2FN6Uj1km4z0X%2Frv9eLEjJ%2Fm3z8wqQu%2BhXUZBs0365yEujjDPpFaztCM7qcuCqkTAoyX9lvbJdevA5A%3D%3D&X-Amz-SignedHeaders=host&X-Amz-Signature=1793b6427087c2a3008f12e3563a4c76edc5fcd9827db0f23ad0280f3004603d\n",
      "Downloading adjusted EOD price data...\n",
      "sending request https://data.nasdaq.com/api/v3/datatables/QUOTEMEDIA/PRICES\n",
      "response <Response [200]> <bound method Response.json of <Response [200]>>\n",
      "Downloading data from https://aws-gis-link-pro-us-east-1-datahub.s3.amazonaws.com/export/QUOTEMEDIA/PRICES/QUOTEMEDIA_PRICES_9c97ee3dc8f78b67ea3eec317439bed5.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAX5EW3SB5G2XBDJ22%2F20241018%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241018T174847Z&X-Amz-Expires=1800&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEOL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJIMEYCIQDmeS%2FLfxevc5JOZ2LDxJFIOITXzlMJKYQgQxZPxi5VPwIhAK4tI6Ri7lktE89r5KUjRyfr2lfiaYDo73ZSGRLPo14gKowFCEsQAhoMNTQzNjI5NzQyMjAyIgwCCoCBu3mt%2FLodTjMq6QTR33wJawZsZb5lqKofzWdWz4mQyETce752IUyYRBrSW5xqG6gohBWTJFMKS67fANCAARhD7Ho85I8eOMhJZOjzUuBcA%2F0x%2Fln4q7DGhp85VyYHCFNP5XYWe4ddR8s3mNg9vMERqdQBZxKID06xBLxSkPGiYLm7jVEEeAcb1sg4RebGI3EuZ0prT2iMZseizfhXdGfy2vuvtNhTNigZs2S9682t968UpEK%2FhocgM4%2FPvoYXawk4mVvpT7J0fctA%2B4tu1jV4SZkXBmPnfAgqwcK59oa0Pqg5T0KJV8slzSB8yctxRQrvLA5zw7G7ZXXtynIL4RpZeaBXRD8PbTiGM3nWzu4mYjV97K3wrAiPToNd7HHwnRitwouqjaShQh5Zf2ZFnKHusULocIT0rsfRga0Lo%2FNEid%2Fgj5DyHFJGl2SxK55w6F3%2BfL0zg6VHya9gqTwdTlrkhZklkPPLmcFDfqAjUYUjyo3ihpzUeJR1F86JOcvnH4oRi%2FuuHuljEp%2Fxf0NHrM7qHVGTi8Qo87hL4ggalJKhcMxqD%2BIK1zaylqLmgntW23HWf2%2F5pn4es2aCz5SZ0iFKdQA%2BdXGBz06Xpvvxuibl4D%2B3rrzvZ3w0y1jDAOmMc%2FBFPrWv3Cyx1M%2FQ2o013AvY7vE3bHNF7qUI3wRojL%2BZMUlywl2N5AWo29Akm9upHiNlG2aWctgi99O1irGNOlXMApca7DAZuMpCgjtl8sgVpMIlRUYRtoHo7wnMzEi%2FzmYeqVWS8Jilek1FS4lkkoHagQsGWHTvgOuGcnwYi2r6xjqjzRn%2BebfT60RGKoZ81NWqzrfKujD%2Fvsq4BjqZAeiNuibBKqRoFsbHNfvx9ikkWyBuBx5e1htmtDpVrt8cFo91p55fPqUcQNOeHoNfzJqv%2F5xsXYEbZCtuJetfzk%2BHV8KdySGJjwnYJVZRVMNjLCu%2FhTrhc9p0uQ%2B%2BNI6UNPdYUVbrnGZhQCh0uvtYpXZ0%2BGRYyuXturhHeVVxuRllrT2nI%2FfYHBdWU5JsMEMo1uqTufXMky8POg%3D%3D&X-Amz-SignedHeaders=host&X-Amz-Signature=e903556aadd0e4e0f0f30f8621c367add4511248cab4d8a620c702b2d454b9fb\n",
      "Storing data in H5 format...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object dtype dtype('O') has no native HDF5 equivalent",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 69\u001b[0m\n\u001b[1;32m     67\u001b[0m tickers_group \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mcreate_group(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtickers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m tickers_df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m---> 69\u001b[0m     \u001b[43mtickers_group\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtickers_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Store prices data\u001b[39;00m\n\u001b[1;32m     72\u001b[0m prices_group \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mcreate_group(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/zip312/lib/python3.12/site-packages/h5py/_hl/group.py:183\u001b[0m, in \u001b[0;36mGroup.create_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    180\u001b[0m         parent_path, name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    181\u001b[0m         group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequire_group(parent_path)\n\u001b[0;32m--> 183\u001b[0m dsid \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_new_dset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m dset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mDataset(dsid)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dset\n",
      "File \u001b[0;32m~/anaconda3/envs/zip312/lib/python3.12/site-packages/h5py/_hl/dataset.py:86\u001b[0m, in \u001b[0;36mmake_new_dset\u001b[0;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter, rdcc_nslots, rdcc_nbytes, rdcc_w0)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     85\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[0;32m---> 86\u001b[0m     tid \u001b[38;5;241m=\u001b[39m \u001b[43mh5t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpy_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Legacy\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m((compression, shuffle, fletcher32, maxshape, scaleoffset)) \u001b[38;5;129;01mand\u001b[39;00m chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32mh5py/h5t.pyx:1663\u001b[0m, in \u001b[0;36mh5py.h5t.py_create\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5t.pyx:1687\u001b[0m, in \u001b[0;36mh5py.h5t.py_create\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5t.pyx:1747\u001b[0m, in \u001b[0;36mh5py.h5t.py_create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object dtype dtype('O') has no native HDF5 equivalent"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import h5py\n",
    "from datetime import datetime\n",
    "import io\n",
    "import zipfile\n",
    "\n",
    "# Set up API key and base URL\n",
    "API_KEY = \"tw2sxkKZo_y1UvMcnSux\"\n",
    "BASE_URL = \"https://data.nasdaq.com/api/v3/datatables/QUOTEMEDIA\"\n",
    "\n",
    "# Function to download data from API\n",
    "def get_data(endpoint, params):\n",
    "    url = f\"{BASE_URL}/{endpoint}\"\n",
    "    params[\"api_key\"] = API_KEY\n",
    "    print(f'sending request {url}')\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        print(f'response {response} {response.json}')\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"API request failed with status code {response.status_code}\")\n",
    "\n",
    "# Function to download and process ZIP file\n",
    "def download_and_process_zip(url):\n",
    "    print(f\"Downloading data from {url}\")\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        z = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "        csv_filename = z.namelist()[0]  # Assume the first file in the ZIP is the CSV we want\n",
    "        with z.open(csv_filename) as f:\n",
    "            df = pd.read_csv(f)\n",
    "        return df\n",
    "    else:\n",
    "        raise Exception(f\"Failed to download ZIP file. Status code: {response.status_code}\")\n",
    "\n",
    "# Download tickers\n",
    "print(\"Downloading tickers...\")\n",
    "tickers_response = get_data(\"TICKERS\", {\"qopts.export\": \"true\"})\n",
    "tickers_download_link = tickers_response['datatable_bulk_download']['file']['link']\n",
    "tickers_df = download_and_process_zip(tickers_download_link)\n",
    "\n",
    "# Download adjusted EOD price data\n",
    "print(\"Downloading adjusted EOD price data...\")\n",
    "start_date = \"2000-01-01\"\n",
    "end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "params = {\n",
    "    \"date.gte\": start_date,\n",
    "    \"date.lte\": end_date,\n",
    "    \"qopts.columns\": \"ticker,date,adj_open,adj_high,adj_low,adj_close,adj_volume\",\n",
    "    \"qopts.export\": \"true\"\n",
    "}\n",
    "\n",
    "price_response = get_data(\"PRICES\", params)\n",
    "price_download_link = price_response['datatable_bulk_download']['file']['link']\n",
    "prices_df = download_and_process_zip(price_download_link)\n",
    "\n",
    "# Convert date column to datetime\n",
    "prices_df[\"date\"] = pd.to_datetime(prices_df[\"date\"])\n",
    "\n",
    "# Store data in H5 format\n",
    "print(\"Storing data in H5 format...\")\n",
    "with h5py.File(\"quotemedia_eod_data.h5\", \"w\") as f:\n",
    "    # Store tickers data\n",
    "    tickers_group = f.create_group(\"tickers\")\n",
    "    for column in tickers_df.columns:\n",
    "        tickers_group.create_dataset(column, data=tickers_df[column].values)\n",
    "    \n",
    "    # Store prices data\n",
    "    prices_group = f.create_group(\"prices\")\n",
    "    for column in prices_df.columns:\n",
    "        if column == \"date\":\n",
    "            prices_group.create_dataset(column, data=prices_df[column].astype(int))\n",
    "        else:\n",
    "            prices_group.create_dataset(column, data=prices_df[column].values)\n",
    "\n",
    "print(\"Data successfully stored in quotemedia_eod_data.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>exchange</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BIOA_WS</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>BioAmber Inc. Warrant expiring May 9 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CDE_WS</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>Coeur D'Alene Mines Corporation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FINQ</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>Purefunds Solactive FinTech ETF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMED</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>PureFunds ETFx HealthTech ETF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CVETV</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>Covetrus Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22977</th>\n",
       "      <td>ATAKR</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>Aurora Technology Acquisition Corp. Rights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22978</th>\n",
       "      <td>MURF</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>Conduit Pharmaceuticals Inc Com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22979</th>\n",
       "      <td>RACY</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>Relativity Acquisition Corp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22980</th>\n",
       "      <td>ACAX</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>Alset Capital Acquisition Corp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22981</th>\n",
       "      <td>AXAC_R</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>AXIOS Sustainable Growth Acquisition Corporati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22982 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ticker exchange                                       company_name\n",
       "0      BIOA_WS     NYSE          BioAmber Inc. Warrant expiring May 9 2017\n",
       "1       CDE_WS     NYSE                    Coeur D'Alene Mines Corporation\n",
       "2         FINQ   NASDAQ                    Purefunds Solactive FinTech ETF\n",
       "3         IMED   NASDAQ                      PureFunds ETFx HealthTech ETF\n",
       "4        CVETV   NASDAQ                                      Covetrus Inc.\n",
       "...        ...      ...                                                ...\n",
       "22977    ATAKR   NASDAQ         Aurora Technology Acquisition Corp. Rights\n",
       "22978     MURF   NASDAQ                    Conduit Pharmaceuticals Inc Com\n",
       "22979     RACY   NASDAQ                       Relativity Acquisition Corp.\n",
       "22980     ACAX   NASDAQ                    Alset Capital Acquisition Corp.\n",
       "22981   AXAC_R     NYSE  AXIOS Sustainable Growth Acquisition Corporati...\n",
       "\n",
       "[22982 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zipline python 3.12",
   "language": "python",
   "name": "zip312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
